{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8406e70e",
   "metadata": {},
   "source": [
    "# Stock Price Prediction Across Market Sectors\n",
    "\n",
    "This project applies machine learning to the problem of stock price prediction, with an emphasis on sector-level diversity and company-level representation. The analysis covers all 11 sectors defined by the Global Industry Classification Standard (GICS). For each sector, a leading stock has been selected from a predefined list of 22 well-established and widely traded companies.\n",
    "\n",
    "The goal is to develop a generalizable and reproducible prediction pipeline, while gaining insight into the behavior of stocks across different industries. \n",
    "\n",
    "### GICS Sectors Covered:\n",
    "- Information Technology  \n",
    "- Health Care  \n",
    "- Financials  \n",
    "- Consumer Discretionary  \n",
    "- Communication Services  \n",
    "- Industrials  \n",
    "- Consumer Staples  \n",
    "- Energy  \n",
    "- Utilities  \n",
    "- Real Estate  \n",
    "- Materials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b822f7",
   "metadata": {},
   "source": [
    "### ðŸ“ˆ Dataset\n",
    "\n",
    "This project uses historical daily stock price data downloaded using the [Yahoo Finance API](https://pypi.org/project/yfinance/). The dataset includes Adjusted Close, Open, High, Low, Volume, and Close prices.\n",
    "\n",
    "We selected 22 companies across 11 sectors of the US stock market:\n",
    "\n",
    "| Sector                    | Tickers         |\n",
    "|--------------------------|-----------------|\n",
    "| Information Technology   | AAPL, MSFT      |\n",
    "| Health Care              | JNJ, UNH        |\n",
    "| Financials               | JPM, BAC        |\n",
    "| Consumer Discretionary   | AMZN, TSLA      |\n",
    "| Communication Services   | GOOGL, META     |\n",
    "| Industrials              | UNP, RTX        |\n",
    "| Consumer Staples         | PG, KO          |\n",
    "| Energy                   | XOM, CVX        |\n",
    "| Utilities                | NEE, DUK        |\n",
    "| Real Estate              | AMT, PLD        |\n",
    "| Materials                | LIN, SHW        |\n",
    "\n",
    "These companies were selected due to their market leadership, high liquidity, and rich historical data. They serve as strong representatives of their sectors and offer a diverse foundation for building and evaluating time series forecasting models.\n",
    "\n",
    "Raw data is saved in `data/raw/` as individual CSV files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62721367",
   "metadata": {},
   "source": [
    "### Basic Feature Engineering: \n",
    "Adding:\n",
    "- High-Low\n",
    "- Price-Open\n",
    "- lag features for closing price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f1ad131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: modified_RTX.csv\n",
      "Processed and saved: modified_SHW.csv\n",
      "Processed and saved: modified_CVX.csv\n",
      "Processed and saved: modified_XOM.csv\n",
      "Processed and saved: modified_TSLA.csv\n",
      "Processed and saved: modified_AMT.csv\n",
      "Processed and saved: modified_META.csv\n",
      "Processed and saved: modified_NEE.csv\n",
      "Processed and saved: modified_UNP.csv\n",
      "Processed and saved: modified_GOOGL.csv\n",
      "Processed and saved: modified_AAPL.csv\n",
      "Processed and saved: modified_BAC.csv\n",
      "Processed and saved: modified_KO.csv\n",
      "Processed and saved: modified_JNJ.csv\n",
      "Processed and saved: modified_PG.csv\n",
      "Processed and saved: modified_DUK.csv\n",
      "Processed and saved: modified_UNH.csv\n",
      "Processed and saved: modified_AMZN.csv\n",
      "Processed and saved: modified_JPM.csv\n",
      "Processed and saved: modified_LIN.csv\n",
      "Processed and saved: modified_MSFT.csv\n",
      "Processed and saved: modified_PLD.csv\n"
     ]
    }
   ],
   "source": [
    "# This script creates High-Low, Price-Open and lagged features for closed prices for the past 10 trading days\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the directory containing your stock CSVs\n",
    "directory = '/Users/beatawyspianska/Desktop/AIML_Projects/predict_stock_price/stock-price-predictor/data/raw/modified' # Replace with your actual path\n",
    "\n",
    "# Loop through all CSV files in the folder\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        \n",
    "        # Load the CSV\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_cols = ['High', 'Low', 'Close', 'Open']\n",
    "        if not all(col in data.columns for col in required_cols):\n",
    "            print(f\"Skipping {file}: missing required columns.\")\n",
    "            continue\n",
    "\n",
    "        # Add engineered features\n",
    "        data['High-Low'] = data['High'] - data['Low']\n",
    "        data['Price-Open'] = data['Close'] - data['Open']\n",
    "        \n",
    "        # Create lag features for 'Close'\n",
    "        for i in range(1, 21):\n",
    "            data[f'Close_lag{i}'] = data['Close'].shift(i)\n",
    "        \n",
    "        # Drop rows with any NaNs caused by lagging\n",
    "        data = data.dropna(subset=[f'Close_lag{n}' for n in range(1, 21)]).reset_index(drop=True)\n",
    "\n",
    "        # Save the modified file back\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326db57",
   "metadata": {},
   "source": [
    "### Let's create our Target column\n",
    "\n",
    "Since we are predicting the next-day Close, our target will be as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = Path(\"/Users/beatawyspianska/Desktop/AIML_Projects/predict_stock_price/stock-price-predictor/data/raw/modified\")\n",
    "output_folder = Path(\"/Users/beatawyspianska/Desktop/AIML_Projects/predict_stock_price/stock-price-predictor/data/processed\")\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define a function to add features\n",
    "def engineer_features(df):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Ensure datetime format and sort\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "# Basic price features\n",
    "    df['RollingMean_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['RollingStd_5'] = df['Close'].rolling(window=5).std()\n",
    "    df['RollingMean_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['RollingStd_10'] = df['Close'].rolling(window=10).std()\n",
    "    df['RollingMean_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['RollingStd_20'] = df['Close'].rolling(window=20).std()\n",
    "\n",
    "# Price momentum\n",
    "    df['Return_1'] = df['Close'].pct_change(1)\n",
    "    df['Return_5'] = df['Close'].pct_change(5)\n",
    "    df['Return_10'] = df['Close'].pct_change(10)\n",
    "    df['Return_20'] = df['Close'].pct_change(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
